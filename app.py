import streamlit as st
import os
import requests
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import io

st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

# å¼ºåˆ¶ä½¿ç”¨æ–°æ–‡ä»¶åï¼Œé¿å…è¯»å–åˆ°æ—§çš„æŸåæ–‡ä»¶
MODEL_URL = "https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/2_4_paprika.onnx"
MODEL_FILE = "anime_model_v2.onnx"

def download_model():
    # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODEL_FILE):
        st.info("ğŸš€ æ­£åœ¨ä¸‹è½½ AI æ¨¡å‹ (çº¦8MB)ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        try:
            # ä¼ªè£…æµè§ˆå™¨å¤´ä¿¡æ¯
            headers = {'User-Agent': 'Mozilla/5.0'}
            r = requests.get(MODEL_URL, headers=headers, stream=True)
            
            with open(MODEL_FILE, 'wb') as f:
                for chunk in r.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # æ ¡éªŒæ–‡ä»¶å¤§å°ï¼Œé˜²æ­¢ä¸‹è½½ç©ºæ–‡ä»¶
            if os.path.getsize(MODEL_FILE) < 1000000:
                os.remove(MODEL_FILE)
                st.error("âŒ ä¸‹è½½å¤±è´¥ï¼šæ–‡ä»¶è¿‡å°ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•")
                st.stop()
                
            st.success("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
            st.stop()

def process_image(image, size=512):
    # å›¾ç‰‡é¢„å¤„ç†
    image = np.array(image.convert('RGB'))
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    h, w = image.shape[:2]
    
    scale = size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    new_h = new_h - (new_h % 32)
    new_w = new_w - (new_w % 32)
    
    if new_h == 0 or new_w == 0: return None
    
    image = cv2.resize(image, (new_w, new_h))
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    download_model()
    
    try:
        session = ort.InferenceSession(MODEL_FILE)
    except Exception as e:
        if os.path.exists(MODEL_FILE):
            os.remove(MODEL_FILE)
        st.error(f"æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œå·²è‡ªåŠ¨æ¸…ç†åæ–‡ä»¶ã€‚è¯·åˆ·æ–°é¡µé¢é‡è¯•ï¼\né”™è¯¯: {e}")
        st.stop()

    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    if img_input is None: return None
    
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    fake_img = fake_img.squeeze()
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(fake_img)

# --- ä¸»é¡µé¢ ---
st.title("ğŸ¨ ç…§ç‰‡è½¬åŠ¨æ¼«ç¥å™¨")
st.write("ä¸Šä¼ ç…§ç‰‡ï¼Œä¸€é”®ç”ŸæˆäºŒæ¬¡å…ƒå½¢è±¡ï¼")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    st.image(original_image, caption="åŸå›¾", use_column_width=True)
    
    if st.button("âš¡ å¼€å§‹è½¬æ¢", type="primary"):
        with st.spinner("æ­£åœ¨ç”Ÿæˆä¸­..."):
            anime_image = run_inference(original_image)
            if anime_image:
                st.image(anime_image, caption="åŠ¨æ¼«æ•ˆæœ", use_column_width=True)
