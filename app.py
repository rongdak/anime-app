import streamlit as st
import os
import requests
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import io

# --- 1. é¡µé¢é…ç½® (å¿…é¡»æ”¾åœ¨ç¬¬ä¸€è¡Œ) ---
st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

# --- 2. æ ¸å¿ƒè®¾ç½® ---
# æ¨¡å‹ä¸‹è½½åœ°å€ (ä½¿ç”¨Paprikaé£æ ¼ï¼Œæ•ˆæœè¾ƒå¥½)
MODEL_URL = "https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/2_4_paprika.onnx"
MODEL_FILE = "model.onnx"

def download_model_if_needed():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½"""
    if not os.path.exists(MODEL_FILE):
        progress_text = st.empty()
        progress_text.info("ğŸš€ é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½AIæ¨¡å‹ (çº¦8MB)...è¯·ç¨å€™")
        try:
            r = requests.get(MODEL_URL)
            with open(MODEL_FILE, 'wb') as f:
                f.write(r.content)
            progress_text.success("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        except Exception as e:
            progress_text.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            st.stop()

def process_image(image, size=512):
    """å›¾ç‰‡é¢„å¤„ç†"""
    image = np.array(image.convert('RGB'))
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    h, w = image.shape[:2]
    
    # ç¼©æ”¾å›¾ç‰‡ï¼Œé¿å…å†…å­˜æº¢å‡º
    scale = size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    new_h = new_h - (new_h % 32)
    new_w = new_w - (new_w % 32)
    
    if new_h == 0 or new_w == 0: return None
    
    image = cv2.resize(image, (new_w, new_h))
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    """æ‰§è¡ŒAIè½¬æ¢"""
    download_model_if_needed()
    
    # åŠ è½½æ¨¡å‹
    session = ort.InferenceSession(MODEL_FILE)
    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    if img_input is None: return None
    
    # æ¨ç†
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    # åå¤„ç†
    fake_img = fake_img.squeeze()
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(fake_img)

# --- 3. ç•Œé¢è®¾è®¡ ---
st.title("ğŸ¨ ç…§ç‰‡è½¬åŠ¨æ¼«ç¥å™¨")
st.markdown("ä¸ç”¨å»æ—¥æœ¬ï¼Œä¸€é”®ç”Ÿæˆå®«å´éªç”»é£ï¼")

uploaded_file = st.file_uploader("ç‚¹å‡»ä¸Šä¼ ä¸€å¼ ç…§ç‰‡ (äººåƒ/é£æ™¯)", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    st.image(original_image, caption="åŸå›¾", use_column_width=True)
    
    if st.button("âš¡ å¼€å§‹è½¬æ¢", type="primary"):
        with st.spinner("AI æ­£åœ¨ç–¯ç‹‚ç»˜ç”»ä¸­..."):
            try:
                anime_image = run_inference(original_image)
                
                st.success("è½¬æ¢æˆåŠŸï¼")
                st.image(anime_image, caption="åŠ¨æ¼«æ•ˆæœ", use_column_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                buf = io.BytesIO()
                anime_image.save(buf, format="PNG")
                byte_im = buf.getvalue()
                
                st.download_button(
                    label="ğŸ’¾ ä¿å­˜å›¾ç‰‡",
                    data=byte_im,
                    file_name="anime_result.png",
                    mime="image/png"
                )
            except Exception as e:
                st.error(f"å‡ºé”™å•¦: {e}")
