import streamlit as st
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import os
import io

st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

MODEL_FILE = "2_4_paprika.onnx"

def resize_crop_center(image, target_size=512):
    """
    æ ¸å¿ƒæ”¹è¿›ï¼šä¸­å¿ƒè£å‰ªæ¨¡å¼
    ä¸æ‹‰ä¼¸å›¾ç‰‡ï¼Œè€Œæ˜¯æˆªå–ä¸­é—´çš„æ­£æ–¹å½¢åŒºåŸŸï¼Œä¿è¯äººç‰©ä¸å˜å½¢ã€‚
    """
    h, w = image.shape[:2]
    
    # 1. è®¡ç®—è£å‰ªåŒºåŸŸ
    short_edge = min(h, w)
    start_h = (h - short_edge) // 2
    start_w = (w - short_edge) // 2
    
    # 2. è¿›è¡Œè£å‰ª (å¾—åˆ°æ­£æ–¹å½¢)
    cropped_img = image[start_h:start_h+short_edge, start_w:start_w+short_edge]
    
    # 3. ç¼©æ”¾åˆ°ç›®æ ‡å¤§å° (512x512)
    resized_img = cv2.resize(cropped_img, (target_size, target_size))
    return resized_img

def process_image(image):
    image = np.array(image.convert('RGB'))
    
    # ä½¿ç”¨æ–°çš„è£å‰ªå‡½æ•°
    image = resize_crop_center(image)
    
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = image.transpose(2, 0, 1) # HWC -> CHW
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    if not os.path.exists(MODEL_FILE):
        st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {MODEL_FILE}ï¼Œè¯·ç¡®ä¿å·²ä¸Šä¼ åˆ°GitHubã€‚")
        st.stop()

    try:
        sess_options = ort.SessionOptions()
        sess_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_BASIC
        session = ort.InferenceSession(MODEL_FILE, sess_options)
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å‡ºé”™ï¼Œå¯èƒ½æ˜¯æ–‡ä»¶æ²¡ä¼ å¯¹ã€‚è¯¦ç»†é”™è¯¯: {e}")
        st.stop()

    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    
    # æ¨ç†
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    # åå¤„ç†
    fake_img = fake_img.squeeze()
    fake_img = fake_img.transpose(1, 2, 0)
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    
    return Image.fromarray(fake_img)

# --- ä¸»é¡µé¢ ---
st.title("ğŸ¨ AI åŠ¨æ¼«ç»˜å›¾ (å®«å´éªç‰ˆ)")
st.info("ğŸ’¡è™½ç„¶èƒŒæ™¯ä¼šå˜å°‘ï¼Œä½†äººè„¸ä¼šæ¸…æ™°å¾ˆå¤šï¼å»ºè®®ä¸Šä¼ äººè„¸è¾ƒå¤§çš„ç…§ç‰‡ã€‚")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ ç…§ç‰‡", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    # æç¤ºç”¨æˆ·å°†è¿›è¡Œè£å‰ª
    st.image(original_image, caption="åŸå›¾ (å°†æˆªå–ä¸­å¿ƒæ­£æ–¹å½¢åŒºåŸŸ)", use_column_width=True)
    
    if st.button("âš¡ ç«‹å³è½¬æ¢", type="primary"):
        with st.spinner("AI æ­£åœ¨ç²¾ç»†ç»˜åˆ¶ä¸­..."):
            try:
                anime_image = run_inference(original_image)
                if anime_image:
                    st.image(anime_image, caption="å®«å´éªé£æ ¼æ•ˆæœ", use_column_width=True)
                    
                    # ä¸‹è½½æŒ‰é’®
                    buf = io.BytesIO()
                    anime_image.save(buf, format="PNG")
                    st.download_button(
                        label="ğŸ“¥ ä¿å­˜é«˜æ¸…å¤§å›¾",
                        data=buf.getvalue(),
                        file_name="anime_hayao.png",
                        mime="image/png"
                    )
            except Exception as e:
                st.error(f"å‡ºé”™å•¦: {e}")
