import streamlit as st
import os
import requests
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import io

st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

# --- å…³é”®ä¿®æ”¹ï¼šæ”¹äº†æ–‡ä»¶åï¼Œå¼ºåˆ¶ç³»ç»Ÿé‡æ–°ä¸‹è½½ ---
MODEL_URL = "https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/2_4_paprika.onnx"
MODEL_FILE = "anime_model_v2.onnx" # æ”¹åäº†ï¼Œè¿™æ ·ç³»ç»Ÿå°±ä¸ä¼šç”¨ä¹‹å‰é‚£ä¸ªåæ–‡ä»¶äº†

def download_model():
    """ä¸‹è½½æ¨¡å‹ï¼Œå¢åŠ é˜²æŠ¥é”™æœºåˆ¶"""
    if not os.path.exists(MODEL_FILE):
        st.info("ğŸš€ æ­£åœ¨ä¸‹è½½ AI æ¨¡å‹ (çº¦8MB)ï¼Œè¯·è€å¿ƒç­‰å¾… 1-2 åˆ†é’Ÿ...")
        try:
            # å¢åŠ  headers ä¼ªè£…æˆæµè§ˆå™¨ï¼Œé˜²æ­¢è¢«æ‹¦æˆª
            headers = {'User-Agent': 'Mozilla/5.0'}
            r = requests.get(MODEL_URL, headers=headers, stream=True)
            
            with open(MODEL_FILE, 'wb') as f:
                for chunk in r.iter_content(chunk_size=1024):
                    if chunk:
                        f.write(chunk)
            
            # æ£€æŸ¥ä¸‹è½½æ˜¯å¦æˆåŠŸï¼ˆæ–‡ä»¶æ˜¯å¦å¤ªå°ï¼‰
            if os.path.getsize(MODEL_FILE) < 1000000: # å¦‚æœå°äº1MBè‚¯å®šä¸å¯¹
                os.remove(MODEL_FILE)
                st.error("âŒ æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼ˆæ–‡ä»¶è¿‡å°ï¼‰ï¼Œè¯·åˆ·æ–°é¡µé¢é‡è¯•ã€‚")
                st.stop()
                
            st.success("âœ… æ¨¡å‹ä¸‹è½½æˆåŠŸï¼")
        except Exception as e:
            st.error(f"âŒ ä¸‹è½½å‡ºé”™: {e}")
            st.stop()

def process_image(image, size=512):
    image = np.array(image.convert('RGB'))
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    h, w = image.shape[:2]
    
    scale = size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    new_h = new_h - (new_h % 32)
    new_w = new_w - (new_w % 32)
    
    if new_h == 0 or new_w == 0: return None
    
    image = cv2.resize(image, (new_w, new_h))
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    download_model() # ç¡®ä¿æ¨¡å‹å­˜åœ¨
    
    try:
        session = ort.InferenceSession(MODEL_FILE)
    except Exception as e:
        # å¦‚æœåŠ è½½å¤±è´¥ï¼Œè‡ªåŠ¨åˆ é™¤åæ–‡ä»¶ï¼Œæç¤ºç”¨æˆ·åˆ·æ–°
        if os.path.exists(MODEL_FILE):
            os.remove(MODEL_FILE)
        st.error(f"æ¨¡å‹æ–‡ä»¶æŸåï¼Œå·²è‡ªåŠ¨åˆ é™¤ã€‚è¯·åˆ·æ–°é¡µé¢é‡è¯•ï¼é”™è¯¯ä¿¡æ¯: {e}")
        st.stop()

    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    if img_input is None: return None
    
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    fake_img = fake_img.squeeze()
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(fake_img)

st.title("ğŸ¨ ç…§ç‰‡è½¬åŠ¨æ¼«ç¥å™¨")
st.write("ä¸Šä¼ ç…§ç‰‡ï¼Œä¸€é”®å˜èº«å®«å´éªç”»é£ï¼")

uploaded_file = st.file_uploader("è¯·é€‰æ‹©ä¸€å¼ å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    st.image(original_image, caption="åŸå›¾", use_column_width=True)
    
    if st.button("âš¡ å¼€å§‹è½¬æ¢", type="primary"):
        with st.spinner("æ­£åœ¨æ–½å±•é­”æ³•..."):
            anime_image = run_inference(original_image)
            if anime_image:
                st.image(anime_image, caption="åŠ¨æ¼«æ•ˆæœ", use_column_width=True)import streamlit as st
import os
import requests
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import io

# --- 1. é¡µé¢é…ç½® (å¿…é¡»æ”¾åœ¨ç¬¬ä¸€è¡Œ) ---
st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

# --- 2. æ ¸å¿ƒè®¾ç½® ---
# æ¨¡å‹ä¸‹è½½åœ°å€ (ä½¿ç”¨Paprikaé£æ ¼ï¼Œæ•ˆæœè¾ƒå¥½)
MODEL_URL = "https://github.com/bryandlee/animegan2-pytorch/raw/main/weights/2_4_paprika.onnx"
MODEL_FILE = "model.onnx"

def download_model_if_needed():
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨ï¼Œä¸å­˜åœ¨åˆ™è‡ªåŠ¨ä¸‹è½½"""
    if not os.path.exists(MODEL_FILE):
        progress_text = st.empty()
        progress_text.info("ğŸš€ é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨ä¸‹è½½AIæ¨¡å‹ (çº¦8MB)...è¯·ç¨å€™")
        try:
            r = requests.get(MODEL_URL)
            with open(MODEL_FILE, 'wb') as f:
                f.write(r.content)
            progress_text.success("âœ… æ¨¡å‹ä¸‹è½½å®Œæˆï¼")
        except Exception as e:
            progress_text.error(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
            st.stop()

def process_image(image, size=512):
    """å›¾ç‰‡é¢„å¤„ç†"""
    image = np.array(image.convert('RGB'))
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    h, w = image.shape[:2]
    
    # ç¼©æ”¾å›¾ç‰‡ï¼Œé¿å…å†…å­˜æº¢å‡º
    scale = size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    new_h = new_h - (new_h % 32)
    new_w = new_w - (new_w % 32)
    
    if new_h == 0 or new_w == 0: return None
    
    image = cv2.resize(image, (new_w, new_h))
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    """æ‰§è¡ŒAIè½¬æ¢"""
    download_model_if_needed()
    
    # åŠ è½½æ¨¡å‹
    session = ort.InferenceSession(MODEL_FILE)
    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    if img_input is None: return None
    
    # æ¨ç†
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    # åå¤„ç†
    fake_img = fake_img.squeeze()
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(fake_img)

# --- 3. ç•Œé¢è®¾è®¡ ---
st.title("ğŸ¨ ç…§ç‰‡è½¬åŠ¨æ¼«ç¥å™¨")
st.markdown("ä¸ç”¨å»æ—¥æœ¬ï¼Œä¸€é”®ç”Ÿæˆå®«å´éªç”»é£ï¼")

uploaded_file = st.file_uploader("ç‚¹å‡»ä¸Šä¼ ä¸€å¼ ç…§ç‰‡ (äººåƒ/é£æ™¯)", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    st.image(original_image, caption="åŸå›¾", use_column_width=True)
    
    if st.button("âš¡ å¼€å§‹è½¬æ¢", type="primary"):
        with st.spinner("AI æ­£åœ¨ç–¯ç‹‚ç»˜ç”»ä¸­..."):
            try:
                anime_image = run_inference(original_image)
                
                st.success("è½¬æ¢æˆåŠŸï¼")
                st.image(anime_image, caption="åŠ¨æ¼«æ•ˆæœ", use_column_width=True)
                
                # ä¸‹è½½æŒ‰é’®
                buf = io.BytesIO()
                anime_image.save(buf, format="PNG")
                byte_im = buf.getvalue()
                
                st.download_button(
                    label="ğŸ’¾ ä¿å­˜å›¾ç‰‡",
                    data=byte_im,
                    file_name="anime_result.png",
                    mime="image/png"
                )
            except Exception as e:
                st.error(f"å‡ºé”™å•¦: {e}")

