import streamlit as st
import onnxruntime as ort
import numpy as np
import cv2
from PIL import Image
import os

st.set_page_config(page_title="äºŒæ¬¡å…ƒè½¬æ¢å™¨", page_icon="ğŸ¨")

# ç›´æ¥ä½¿ç”¨ä½ åˆšä¸Šä¼ çš„æ–‡ä»¶å
MODEL_FILE = "2_4_paprika.onnx"

def process_image(image, size=512):
    image = np.array(image.convert('RGB'))
    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)
    h, w = image.shape[:2]
    
    scale = size / max(h, w)
    new_h, new_w = int(h * scale), int(w * scale)
    new_h = new_h - (new_h % 32)
    new_w = new_w - (new_w % 32)
    
    if new_h == 0 or new_w == 0: return None
    
    image = cv2.resize(image, (new_w, new_h))
    image = image.astype(np.float32)
    image = image / 127.5 - 1.0
    image = np.expand_dims(image, axis=0)
    return image

def run_inference(image_pil):
    # æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(MODEL_FILE):
        st.error(f"âŒ æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ï¼è¯·ç¡®è®¤ä½ å·²ç»æŠŠ {MODEL_FILE} ä¸Šä¼ åˆ°äº† GitHub ä»“åº“é‡Œã€‚")
        st.stop()

    try:
        session = ort.InferenceSession(MODEL_FILE)
    except Exception as e:
        st.error(f"âŒ æ¨¡å‹åŠ è½½å‡ºé”™: {e}")
        st.stop()

    x_name = session.get_inputs()[0].name
    y_name = session.get_outputs()[0].name
    
    img_input = process_image(image_pil)
    if img_input is None: return None
    
    fake_img = session.run([y_name], {x_name: img_input})[0]
    
    fake_img = fake_img.squeeze()
    fake_img = (fake_img + 1.0) * 127.5
    fake_img = np.clip(fake_img, 0, 255).astype(np.uint8)
    fake_img = cv2.cvtColor(fake_img, cv2.COLOR_BGR2RGB)
    return Image.fromarray(fake_img)

# --- ä¸»é¡µé¢ ---
st.title("ğŸ¨ ç…§ç‰‡è½¬åŠ¨æ¼«ç¥å™¨")
st.write("ä¸Šä¼ ç…§ç‰‡ï¼Œä¸€é”®ç”ŸæˆäºŒæ¬¡å…ƒå½¢è±¡ï¼")

uploaded_file = st.file_uploader("è¯·ä¸Šä¼ å›¾ç‰‡", type=['jpg', 'png', 'jpeg'])

if uploaded_file:
    original_image = Image.open(uploaded_file)
    st.image(original_image, caption="åŸå›¾", use_column_width=True)
    
    if st.button("âš¡ å¼€å§‹è½¬æ¢", type="primary"):
        with st.spinner("AI æ­£åœ¨ç»˜åˆ¶ä¸­..."):
            anime_image = run_inference(original_image)
            if anime_image:
                st.image(anime_image, caption="åŠ¨æ¼«æ•ˆæœ", use_column_width=True)
